{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LeakyReLU, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import svd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "# Fetch stock data from Yahoo Finance\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return data\n",
    "\n",
    "# Compute technical indicators\n",
    "def compute_technical_indicators(data):\n",
    "    data['SMA30'] = data['Close'].rolling(window=30).mean()\n",
    "    data['SMA100'] = data['Close'].rolling(window=100).mean()\n",
    "    vol_window = 21\n",
    "    data['Volatility'] = data['Close'].pct_change().rolling(window=vol_window).std() * np.sqrt(252)\n",
    "    return data.dropna()\n",
    "\n",
    "# Black-Scholes option pricing model\n",
    "def black_scholes(S, K, T, r, sigma, option_type='call'):\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    if option_type == 'call':\n",
    "        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    elif option_type == 'put':\n",
    "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "\n",
    "# Apply Black-Scholes model to generate option prices\n",
    "def add_option_pricing_features(data):\n",
    "    strike_price = data['Close'] * 1.05\n",
    "    time_to_maturity = 30 / 252\n",
    "    risk_free_rate = 0.01\n",
    "    option_type = 'call'\n",
    "    data['Option_Price'] = black_scholes(data['Close'], strike_price, time_to_maturity, risk_free_rate, data['Volatility'], option_type)\n",
    "    data['Implied_Volatility'] = data['Volatility']\n",
    "    return data\n",
    "\n",
    "# Normalize and apply PCA for dimensionality reduction\n",
    "def preprocess_data(data, n_pca_components=2):\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    # pca = PCA(n_components=n_pca_components)\n",
    "    # data_pca = pca.fit_transform(data_scaled)\n",
    "    # return np.hstack((data_scaled, data_pca))\n",
    "    return data_scaled, scaler\n",
    "\n",
    "# Create sequences for time-series prediction\n",
    "def create_sequences(data, seq_len, pred_len):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_len - pred_len + 1):\n",
    "        sequences.append(data[i:i + seq_len + pred_len])\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Function to create a Hankel matrix\n",
    "def create_hankel_matrix(time_series, window_size):\n",
    "    # Create a Hankel matrix where the columns are shifted versions of the time series\n",
    "    hankel_matrix = np.array([time_series[i:i + window_size] for i in range(len(time_series) - window_size + 1)])\n",
    "    return hankel_matrix\n",
    "\n",
    "# Function to perform SVD on the Hankel matrix\n",
    "def hankel_svd(hankel_matrix):\n",
    "    # Perform SVD on the Hankel matrix\n",
    "    U, Sigma, Vt = svd(hankel_matrix, full_matrices=False)\n",
    "    return U, Sigma, Vt\n",
    "\n",
    "# Build a neural network model\n",
    "def build_model(input_shape, output_len):\n",
    "    model = Sequential([\n",
    "    LSTM(200, activation='relu', return_sequences=False),  # LSTM layer\n",
    "    Dense(180),\n",
    "    LeakyReLU(),\n",
    "    Dense(360),\n",
    "    LeakyReLU(),\n",
    "    Dense(360),\n",
    "    LeakyReLU(),\n",
    "    Dense(output_len)  # Output predictions for \"Close\" prices\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def predict_and_plot(m, ticker, data, s, model, seq_len, pred_len, scaler, cut_off):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    rmse_values = []  # To store RMSE values for each section\n",
    "    section_start_idx = []  # To store the start indices of each 30-day section for placement of RMSE labels\n",
    "    #s.shape[0]\n",
    "    for idx in range(0,cut_off+pred_len , pred_len):  # Loop through each 30-day block\n",
    "    # for idx in range(1): # only first 30 after being trained\n",
    "        # Input remains in 3D for predictio\n",
    "        future_input = s[idx, :seq_len, :].reshape(1, seq_len, -1)  # Keep the 3D shape\n",
    "        future = model.predict(future_input)[0]  # Predict future \"Close\" prices\n",
    "        # Pad the prediction with zeros for the \"Volume\" and \"SMA\" columns\n",
    "        future_padded = np.hstack((future.reshape(-1, 1), np.zeros((future.shape[0], data.shape[1] - 3))))  # Adjust for PCA features\n",
    "\n",
    "        # Inverse transform the padded prediction\n",
    "        future_transform = scaler.inverse_transform(future_padded)[:, 0]  # Extract \"Close\"\n",
    "\n",
    "        # Extract and inverse transform the true \"Close\" values\n",
    "        future_true = s[idx, seq_len:, 0].reshape(-1, 1)  # Use only \"Close\"\n",
    "        future_true_padded = np.hstack((future_true, np.zeros((future_true.shape[0], data.shape[1] - 3))))  # Adjust for PCA features\n",
    "        future_true_transform = scaler.inverse_transform(future_true_padded)[:, 0]  # Extract \"Close\"\n",
    "\n",
    "        # Calculate RMSE for this 30-day section\n",
    "        rmse = np.sqrt(mean_squared_error(future_true_transform, future_transform))\n",
    "        rmse_values.append(rmse)\n",
    "        section_start_idx.append(idx)  # Store the start index for the RMSE label\n",
    "\n",
    "        # Plot the predictions\n",
    "        plt.plot(np.arange(idx, idx + pred_len), future_transform, \n",
    "                # label=\"Train Prediction\" if idx < cut_off else \"Test Prediction\", \n",
    "                 color=\"red\" if idx < cut_off else \"blue\")\n",
    "\n",
    "        # Plot the true values\n",
    "        plt.plot(np.arange(idx, idx + pred_len), future_true_transform, \n",
    "                 #label=\"Train True\" if idx < cut_off else \"Test True\", \n",
    "                 color=\"black\" if idx < cut_off else \"green\")\n",
    "\n",
    "        \n",
    "    \n",
    "    # Add legend and grid\n",
    "    # plt.legend([\"Train Prediction\", \"Train True\", \"Test Prediction\", \"Test True\"])\n",
    "    plt.plot([], [], color=\"red\", label=\"Train Prediction\")  # Dummy plot for legend\n",
    "    plt.plot([], [], color=\"black\", label=\"Train True\")      # Dummy plot for legend\n",
    "    plt.plot([], [], color=\"blue\", label=\"Test Prediction\")  # Dummy plot for legend\n",
    "    plt.plot([], [], color=\"green\", label=\"Test True\")      # Dummy plot for legend\n",
    "    plt.legend()\n",
    "    for idx in range(0, s.shape[0], pred_len): \n",
    "    # Add vertical line to separate each 30-day section\n",
    "        plt.axvline(x=idx + pred_len, color='gray', linestyle='--', linewidth=1)\n",
    "    # Title and labels\n",
    "    \n",
    "    plt.title(f\"{seq_len}-{pred_len} Predictions for {ticker}, model {m}\")\n",
    "    plt.xlabel(\"Trading Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "\n",
    "    # Add RMSE labels below the x-axis at the start of each 30-day section\n",
    "    for i, rmse in zip(section_start_idx, rmse_values):\n",
    "        plt.text(i + pred_len / 2, min(plt.ylim()), f\"{rmse:.0f}\", color=\"teal\", fontsize=10, ha='center', va='top')\n",
    "    plt.text(- 5- pred_len / 2, min(plt.ylim()), f\"RMSE\", color=\"teal\", fontsize=10, ha='center', va='top')\n",
    "    print(rmse_values)\n",
    "    plt.grid(True)\n",
    "    if m == \"PI-LSTM w/ 8 features\":\n",
    "        dir = f\"features+piLSTMdata/{seq_len}-{pred_len}/pilstm_8\"\n",
    "        if not os.path.exists(dir):\n",
    "                os.makedirs(dir)\n",
    "        plt.savefig(f\"{dir}/{ticker}.png\")\n",
    "    return rmse_values[-1] # testing rmse\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "# Call the function\n",
    "\n",
    "def findCorr(x):\n",
    "    corr_matrix = pd.DataFrame(x).corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    ## find the high collinear columns which have a threshold > 0.9 \n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    x_reduced = pd.DataFrame(x).drop(to_drop, axis=1)\n",
    "    print(x_reduced.shape)\n",
    "    return x_reduced\n",
    "\n",
    "\n",
    "# Main workflow\n",
    "def main(tickers):\n",
    "    m = \"PI-LSTM w/ 8 features\"\n",
    "    test_rmse = []\n",
    "    for ticker in tickers:\n",
    "        # Step 1: Fetch data\n",
    "        tsla = fetch_stock_data(ticker, start_date=\"2021-01-01\", end_date=\"2024-09-30\")\n",
    "\n",
    "        # Step 2: Compute indicators\n",
    "        tsla = compute_technical_indicators(tsla)\n",
    "\n",
    "        # Step 3: Add Black-Scholes option pricing\n",
    "        tsla = add_option_pricing_features(tsla)\n",
    "\n",
    "        # Step 4: Prepare data for training\n",
    "        features = ['Close', 'Volume', 'SMA30', 'SMA100', 'Volatility', 'Option_Price']\n",
    "        data = tsla[features].copy()\n",
    "        # Step 5: Perform Hankel Matrix Decomposition\n",
    "        window_size = 50  # Size of the sliding window to form the Hankel matrix\n",
    "        hankel_matrix = create_hankel_matrix(data['Close'].values, window_size)\n",
    "\n",
    "        # Step 6: Perform SVD on the Hankel matrix\n",
    "        U, Sigma, Vt = hankel_svd(hankel_matrix)\n",
    "\n",
    "        # You can choose the first few singular values and modes to add as features\n",
    "        num_modes = 2  # Number of modes to add as features\n",
    "        dmd_modes = U[:, :num_modes]  # Select the modes\n",
    "        dmd_amplitudes = Sigma[:num_modes]  # Select the amplitudes\n",
    "\n",
    "        # Step 7: Normalize and apply PCA for dimensionality reduction\n",
    "        processed_data,scaler = preprocess_data(data)\n",
    "\n",
    "        # Trim the processed_data to match the number of rows in dmd_modes\n",
    "        processed_data_trimmed = processed_data[-dmd_modes.shape[0]:]  # Trim to match the length of dmd_modes\n",
    "\n",
    "        # Combine the Hankel decomposition modes with the processed data\n",
    "        data_combined = np.hstack((processed_data_trimmed, dmd_modes))\n",
    "        reduced_data = findCorr(data_combined)\n",
    "\n",
    "        # View the reduced dataset shape\n",
    "        print(\"Reduced data shape:\", reduced_data.shape)\n",
    "\n",
    "        # Optionally, inspect the remaining columns\n",
    "        print(\"Remaining features:\", data)\n",
    "        # Step 8: Create sequences for time-series prediction\n",
    "        seq_len = 6 * 30  # 6 months of data\n",
    "        pred_len = 20  # Predict the next 20 days\n",
    "        sequences = create_sequences(data_combined, seq_len, pred_len)\n",
    "\n",
    "        # Step 9: Split data into training and testing\n",
    "        cut_off = int(0.95 * sequences.shape[0])\n",
    "        X_train = sequences[:cut_off, :seq_len, :]\n",
    "        X_test = sequences[cut_off:, :seq_len, :]\n",
    "        y_train = sequences[:cut_off, seq_len:, 0]\n",
    "        y_test = sequences[cut_off:, seq_len:, 0]\n",
    "        print(sequences.shape)\n",
    "        \n",
    "        # Step 10: Build and train the model\n",
    "        model = build_model(input_shape=(seq_len, X_train.shape[2]), output_len=pred_len)\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=32,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        test_rmse += [predict_and_plot(m, ticker, data_combined, sequences, model, seq_len, pred_len, scaler, cut_off)]\n",
    "\n",
    "    mse_for_model  = np.mean(test_rmse)\n",
    "    return mse_for_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_22422/480259662.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Option_Price'] = black_scholes(data['Close'], strike_price, time_to_maturity, risk_free_rate, data['Volatility'], option_type)\n",
      "/tmp/ipykernel_22422/480259662.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Implied_Volatility'] = data['Volatility']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 7)\n",
      "Reduced data shape: (792, 7)\n",
      "Remaining features:             0         1         2         3         4         5         7\n",
      "0    0.431013  0.033757  0.389413  0.304344  0.147769  0.081031 -0.014411\n",
      "1    0.413865  0.063016  0.390319  0.304802  0.164409  0.088471 -0.014697\n",
      "2    0.430053  0.053192  0.392286  0.305049  0.172094  0.098058 -0.015320\n",
      "3    0.425890  0.039306  0.393286  0.306220  0.127812  0.065850 -0.015746\n",
      "4    0.423494  0.000000  0.394557  0.307312  0.106194  0.050402 -0.016060\n",
      "..        ...       ...       ...       ...       ...       ...       ...\n",
      "787  0.470070  0.207531  0.375788  0.231508  0.517726  0.376545  0.002340\n",
      "788  0.484215  0.213173  0.383789  0.236102  0.497009  0.368177 -0.001332\n",
      "789  0.493325  0.128550  0.390720  0.240865  0.470698  0.351994 -0.005296\n",
      "790  0.484049  0.136154  0.398166  0.245382  0.464435  0.341966 -0.008748\n",
      "791  0.504721  0.150029  0.404693  0.250065  0.455197  0.345431 -0.012473\n",
      "\n",
      "[792 rows x 7 columns]\n",
      "(593, 200, 8)\n",
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0843\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - loss: 0.0152\n",
      "Epoch 3/100\n",
      "\u001b[1m 3/18\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0108"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tickers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTSLA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 234\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# Step 10: Build and train the model\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_model(input_shape\u001b[38;5;241m=\u001b[39m(seq_len, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]), output_len\u001b[38;5;241m=\u001b[39mpred_len)\n\u001b[0;32m--> 234\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     test_rmse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [predict_and_plot(m, ticker, data_combined, sequences, model, seq_len, pred_len, scaler, cut_off)]\n\u001b[1;32m    243\u001b[0m mse_for_model  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(test_rmse)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tickers = [\"TSLA\"]\n",
    "mse = main(tickers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
